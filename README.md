# BigData_nhom10

## Tá»•ng quan âœ…
Repo nÃ y chá»©a cÃ¡c thÃ nh pháº§n cho **Stream Layer** (Ä‘Ã£ sáºµn sÃ ng) vÃ  **Batch Layer** (Ä‘ang phÃ¡t triá»ƒn). HÆ°á»›ng dáº«n dÆ°á»›i Ä‘Ã¢y giÃºp báº¡n dá»±ng mÃ´i trÆ°á»ng, giáº£ láº­p dá»¯ liá»‡u streaming tá»›i Kafka, xá»­ lÃ½ báº±ng Spark vÃ  Ä‘áº©y káº¿t quáº£ tá»›i Elasticsearch Ä‘á»ƒ Kibana visualize.

---

## YÃªu cáº§u trÆ°á»›c ğŸ”§
- Docker & Docker Compose
- Python 3.8+
- (TÃ¹y chá»n) Java náº¿u Spark cáº§n cháº¡y cá»¥c bá»™
- CÃ i Python packages: `pip install -r requirements.txt`

---

## Stream Layer â€” HÆ°á»›ng dáº«n cháº¡y (Ngáº¯n gá»n) ğŸ”
1. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t:
   - `python -m pip install -r requirements.txt`

2. Cháº¡y Docker Compose Ä‘á»ƒ dá»±ng cÃ¡c thÃ nh pháº§n (Kafka, Elasticsearch, Kibana,...):
   - Di chuyá»ƒn vÃ o thÆ° má»¥c chá»©a docker-compose (vÃ­ dá»¥ `docker/elk_1node_docker`) vÃ  cháº¡y:
     ```bash
     cd docker/elk_1node_docker
     docker compose up -d
     ```
   - Kiá»ƒm tra Elasticsearch:
     ```bash
     curl -u elastic:123123 http://localhost:9200/_cluster/health?pretty
     ```
- Cáº§n cháº¡y 2 file yml trong:
    - elk_1node_docker: dá»±ng elasticsearch, kibana
    - kafka_docker: dá»±ng kafka

3. Giáº£ láº­p dá»¯ liá»‡u real-time tá»›i Kafka:
   - Cháº¡y producer stream:
     ```bash
     python stream/producer_stream.py
     ```
   - Producer sáº½ gá»­i dá»¯ liá»‡u giáº£ láº­p vÃ o topic Ä‘Ã£ cáº¥u hÃ¬nh.

4. Cháº¡y pipeline Spark Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u vÃ  gá»­i káº¿t quáº£ tá»›i Elasticsearch:
   - Sá»­ dá»¥ng `Makefile` trong thÆ° má»¥c `stream`:
     ```bash
     cd stream
     make
     ```
   - Lá»‡nh `make` sáº½ thá»±c thi job Spark (theo cáº¥u hÃ¬nh trong repo) vÃ  Ä‘áº©y káº¿t quáº£ tá»›i Elasticsearch.

5. Má»Ÿ Kibana Ä‘á»ƒ visualize dá»¯ liá»‡u streaming:
   - Máº·c Ä‘á»‹nh Kibana Ä‘Æ°á»£c map tá»›i cá»•ng `5061` â†’ truy cáº­p: `http://localhost:5061`
   - Náº¿u cáº§n má»Ÿ port trÃªn firewall (Ubuntu):
     ```bash
     sudo ufw allow 5061/tcp
     ```

---

## Kiá»ƒm tra & gá»¡ rá»‘i âš ï¸
- Kiá»ƒm tra logs cá»§a cÃ¡c container:
  - `docker compose logs -f`
- Äáº£m báº£o Kafka vÃ  Elasticsearch Ä‘Ã£ cháº¡y trÆ°á»›c khi khá»Ÿi Ä‘á»™ng producer hoáº·c Spark job.
- Náº¿u gáº·p lá»—i káº¿t ná»‘i Elasticsearch, kiá»ƒm tra username/password vÃ  tráº¡ng thÃ¡i cluster (báº±ng `curl` á»Ÿ trÃªn).

---

## Batch Layer ğŸ“¦
- **Äang phÃ¡t triá»ƒn** â€” sáº½ cáº­p nháº­t hÆ°á»›ng dáº«n khi hoÃ n thiá»‡n.

---

## Dá»«ng dá»‹ch vá»¥ & dá»n dáº¹p ğŸ§¹
- Dá»«ng vÃ  xÃ³a volumes (náº¿u cáº§n):
  ```bash
  cd docker/elk_single-node_docker
  docker compose down -v
  ```


---

Náº¿u báº¡n muá»‘n, tÃ´i cÃ³ thá»ƒ bá»• sung cÃ¡c lá»‡nh cá»¥ thá»ƒ cho tá»«ng docker-compose file hoáº·c thÃªm vÃ­ dá»¥ cáº¥u hÃ¬nh Spark/Makefile. ğŸ”§